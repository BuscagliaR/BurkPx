{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(X, Y, repeat, n_splits, scorer, mod, hyperparameters,  n_jobs=None, stratify=True):\n",
    "    # GridSearch Wrapper Fucntion\n",
    "    print(\"Number of repeats run is: \" + str(repeat))\n",
    "    dfL = []\n",
    "    for i in range(0,repeat):\n",
    "        if stratify==True:\n",
    "            cv = StratifiedKFold(n_splits=n_splits, random_state=i, shuffle=True)\n",
    "        else:\n",
    "            cv = KFold(n_splits=n_splits, random_state=i, shuffle=True)\n",
    "        boosted_grid = GridSearchCV(mod, hyperparameters, scoring=scorer, cv=cv, verbose=0, refit=True, error_score=np.nan, return_train_score=True, n_jobs=n_jobs) #n_jobs=n_jobs,\n",
    "        grid_fit = boosted_grid.fit(X, Y)\n",
    "        DF = pd.DataFrame(grid_fit.cv_results_)\n",
    "        DF['Iteration'] = i\n",
    "        dfL.append(DF)\n",
    "    DFall = pd.concat(dfL)\n",
    "    return DFall\n",
    "\n",
    "\n",
    "def OverSampler(parentDIR,df, xfilename, yfilename):\n",
    "    # Oversample small class to balanced data\n",
    "    os.chdir(parentDIR)\n",
    "    df = df.dropna()\n",
    "    X = df.iloc[:,4:].copy()\n",
    "    X['TimeGroup'] = df.TimeGroup.copy()\n",
    "    X = pd.get_dummies(X)\n",
    "    Y = df.Status.copy()\n",
    "\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    Xoversampled, Yoversampled = ros.fit_resample(X, Y)\n",
    "\n",
    "    if not os.path.isdir('OverSampled'):\n",
    "        os.makedirs('OverSampled')\n",
    "    os.chdir('OverSampled')\n",
    "\n",
    "    Xoversampled.to_csv(xfilename, sep='\\t')\n",
    "    Yoversampled.to_csv(yfilename, sep='\\t')\n",
    "    return Xoversampled, Yoversampled"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parentdir = os.getcwd()\n",
    "\n",
    "X = pd.read_csv('W3_predictor.txt', sep='\\t', index_col=0)\n",
    "Y = pd.read_csv('W3_response.txt', sep='\\t', index_col=0).squeeze()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(parentdir)\n",
    "if not os.path.isdir('Results'):\n",
    "    os.makedirs('Results')\n",
    "os.chdir('Results')\n",
    "RAND=np.random.RandomState(4)\n",
    "\n",
    "param_space = {'C':np.logspace(-5,2,4),\n",
    "                'l1_ratio':[float(x) for x in np.linspace(0.1,0.9,4)]}\n",
    "enet = LogisticRegression(penalty = 'elasticnet', solver = 'saga', max_iter=int(1e6))\n",
    "\n",
    "Enet = gridSearch(X=X, Y=Y, repeat=200, n_splits=10, scorer='roc_auc', mod=enet, hyperparameters=param_space, n_jobs=6, stratify=True) #, n_jobs=numCores\n",
    "Enet.to_csv('W3_EnetBurkPx_GridSearch.txt', sep='\\t')\n",
    "Enet['params2'] = Enet['params'].astype(str)\n",
    "print('Finished Enet')\n",
    "\n",
    "\n",
    "param_space = {'C':np.logspace(-5,3,10),\n",
    "                'penalty':['l1', 'l2']}\n",
    "lr = LogisticRegression( solver = 'saga', max_iter=int(1e6))\n",
    "\n",
    "LR = gridSearch(X=X, Y=Y, repeat=200, n_splits=10, scorer='roc_auc', mod=lr, hyperparameters=param_space, n_jobs=6, stratify=True) #, n_jobs=numCores\n",
    "LR.to_csv('W3_LRBurkPx_GridSearch.txt', sep='\\t')\n",
    "LR['params2'] = LR['params'].astype(str)\n",
    "print('Finished LR')\n",
    "\n",
    "\n",
    "param_space = {'learning_rate': np.logspace(-3, -1,4),\n",
    "                'n_estimators': [25, 50],\n",
    "                'subsample': np.linspace(0.2,0.9,3),\n",
    "                'colsample_bytree':np.linspace(0.05, 0.5, 3),\n",
    "                'max_depth':[int(x) for x in np.linspace(3,20,3)]}\n",
    "\n",
    "xgb =  XGBClassifier(objective='binary:logistic', eval_metric='logloss', random_state=RAND) #, scale_pos_weight=len(Y==0)/len(Y==1) BinaryFocalLoss\n",
    "\n",
    "LR = gridSearch(X=X, Y=Y, repeat=200, n_splits=10, scorer='roc_auc', mod=xgb, hyperparameters=param_space, n_jobs=6, stratify=True) #, n_jobs=numCores\n",
    "LR.to_csv('W3_XGBBurkPx_GridSearch.txt', sep='\\t')\n",
    "LR['params2'] = LR['params'].astype(str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Figure Analysis\n",
    "### Enet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = pd.read_csv('W3_EnetBurkPx_GridSearch.txt', sep='\\t', index_col=0)\n",
    "LR['params2'] = LR['params'].astype(str)\n",
    "fig, ax = plt.subplots()\n",
    "sns.boxplot(data=LR, y= 'mean_test_score', x='params2', ax=ax)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalized Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = pd.read_csv('W3_LRBurkPx_GridSearch.txt', sep='\\t', index_col=0)\n",
    "LR['params2'] = LR['params'].astype(str)\n",
    "fig, ax = plt.subplots()\n",
    "sns.boxplot(data=LR, y= 'mean_test_score', x='params2', ax=ax)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = pd.read_csv('W3_XGBBurkPx_GridSearch.txt', sep='\\t', index_col=0)\n",
    "LR['params2'] = LR['params'].astype(str)\n",
    "fig, ax = plt.subplots()\n",
    "sns.boxplot(data=LR, y= 'mean_test_score', x='params2', ax=ax)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(parentdir)\n",
    "os.chdir('Results')\n",
    "\n",
    "LR = pd.read_csv('W3_EnetBurkPx_GridSearch.txt', sep='\\t', index_col=0)\n",
    "W1Enet = LR.loc[LR['params'] ==\"{'C': 0.0021544346900318843, 'l1_ratio': 0.6333333333333333}\"]\n",
    "W1Enet['Model']  = 'ElasticNet'\n",
    "\n",
    "LR = pd.read_csv('W3_LRBurkPx_GridSearch.txt', sep='\\t', index_col=0)\n",
    "W1LASSOWeak=LR.loc[LR['params']== \"{'C': 1000.0, 'penalty': 'l1'}\"].copy()\n",
    "W1LASSOWeak['Model'] = 'LASSO_Weak'\n",
    "\n",
    "W1LASSOstrong=LR.loc[LR['params']== \"{'C': 0.004641588833612777, 'penalty': 'l1'}\"].copy()\n",
    "W1LASSOstrong['Model'] = 'LASSO_Strong'\n",
    "\n",
    "W1RIDGEWeak=LR.loc[LR['params']== \"{'C': 1000.0, 'penalty': 'l2'}\"].copy()\n",
    "W1RIDGEWeak['Model'] = 'Ridge_Weak'\n",
    "\n",
    "W1RIDGEstrong=LR.loc[LR['params']== \"{'C': 0.004641588833612777, 'penalty': 'l2'}\"].copy()\n",
    "W1RIDGEstrong['Model'] = 'Ridge_Strong'\n",
    "\n",
    "\n",
    "LR = pd.read_csv('W3_XGBBurkPx_GridSearch.txt', sep='\\t', index_col=0)\n",
    "W1XGB = LR.loc[LR['params']==\"{'colsample_bytree': 0.05, 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.55}\"]\n",
    "W1XGB['Model'] = 'XGBoost'\n",
    "BEST = pd.concat([W1LASSOWeak, W1LASSOstrong, W1RIDGEWeak, W1RIDGEstrong, W1Enet, W1XGB])\n",
    "\n",
    "BEST['params2'] = BEST['params'].astype(str)\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('colorblind')\n",
    "fig, ax = plt.subplots()\n",
    "sns.boxplot(data=BEST, y= 'mean_test_score', x='Model', hue=None, ax=ax)\n",
    "plt.xticks(rotation=45)\n",
    "ax.set_title('Week3 Model Comparions')\n",
    "\n",
    "fig.savefig('Week3_Model_Comparison_Oversampled_rocAUC.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Validation Set\n",
    "### Enet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "os.chdir('../../ValidationSet')\n",
    "\n",
    "df = pd.read_csv('ValidationSet.txt', sep='\\t', index_col=0)\n",
    "Week3 = df.loc[(df['TimeGroup']=='Week3')|(df['TimeGroup']=='Healthy')]\n",
    "\n",
    "yVAL = Week3.Status.copy()\n",
    "yVAL.replace('Melioid', 1, inplace=True)\n",
    "yVAL.replace('Negative', 0, inplace=True)\n",
    "\n",
    "XVAL = Week2.iloc[:,4:].copy()\n",
    "XVAL = pd.get_dummies(XVAL)\n",
    "\n",
    "ros = RandomUnderSampler(random_state=0)\n",
    "Xunder, Yunder = ros.fit_resample(XVAL, yVAL)\n",
    "\n",
    "\n",
    "enet = LogisticRegression(penalty = 'elasticnet', C=0.0021544346900318843, l1_ratio=0.6333333333333333, solver = 'saga', max_iter=int(1e6)).fit(Xunder, Yunder)\n",
    "# roc_auc_score(y, clf.predict_proba(X)[:, 1])\n",
    "roc_auc_score(Yunder, enet.predict_proba(Xunder)[:, 1])\n",
    "# roc_auc_score(yVAL, enet.decision_function(XVAL))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BurkPXx86",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Mar  8 2023, 04:29:44) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e2c6553b54c3807a40bb80bc101a8fa42e87c4bbf99a205a1d180a38d3d30f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
